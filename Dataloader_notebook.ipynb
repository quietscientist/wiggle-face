{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install torch and pandas before running\n",
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By analysing the keypoints and plotting them, I deduced that the following keypoints correspond to the following face parts:\n",
    "1-33 Chin,\n",
    "34-42 Right_brow,\n",
    "43-51 Left_brow,\n",
    "52-66 Nose,\n",
    "67-75 Right_Eye,\n",
    "76-84 Left_Eye,\n",
    "85-104 Mouth,\n",
    "105 Right_Pupil,\n",
    "106 Left_Pupil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeypointsDataset:\n",
    "    def __init__(self, json_dir):\n",
    "        self.json_dir = json_dir\n",
    "        self.json_files = [f for f in os.listdir(json_dir) if f.endswith('.json')]\n",
    "        self.data = self.load_data()\n",
    "\n",
    "    def keypoint_to_face_part(self, index):\n",
    "        if 1 <= index <= 33:\n",
    "            return \"Chin\"\n",
    "        elif 34 <= index <= 42:\n",
    "            return \"Right_brow\"\n",
    "        elif 43 <= index <= 51:\n",
    "            return \"Left_brow\"\n",
    "        elif 52 <= index <= 66:\n",
    "            return \"Nose\"\n",
    "        elif 67 <= index <= 75:\n",
    "            return \"Right_Eye\"\n",
    "        elif 76 <= index <= 84:\n",
    "            return \"Left_Eye\"\n",
    "        elif 85 <= index <= 104:\n",
    "            return \"Mouth\"\n",
    "        elif index == 105:\n",
    "            return \"Right_Pupil\"\n",
    "        elif index == 106:\n",
    "            return \"Left_Pupil\"\n",
    "        else:\n",
    "            return \"Unknown\"\n",
    "\n",
    "    def load_data(self):\n",
    "        data = []\n",
    "        for json_file in self.json_files:\n",
    "            video_id = os.path.splitext(json_file)[0]\n",
    "            infant_id = video_id.split('_')[-1]  # to extract the number after \"video_\"\n",
    "            print(f\"Processing infant ID: {infant_id}\")\n",
    "            with open(os.path.join(self.json_dir, json_file), 'r') as f:\n",
    "                frames = json.load(f)\n",
    "                for frame_index, frame_data in enumerate(frames):\n",
    "                    frame_id = frame_data[\"frame_id\"]\n",
    "                    # print(f\"  Processing frame {frame_index + 1}/{len(frames)}\")\n",
    "                    for instance_index, instance in enumerate(frame_data[\"instances\"]):\n",
    "                        keypoints = instance[\"keypoints\"]\n",
    "                        keypoint_scores = instance[\"keypoint_scores\"]\n",
    "                        for idx, (kp, score) in enumerate(zip(keypoints, keypoint_scores)):\n",
    "                            # indexing the datapoints for future groupping purposes\n",
    "                            face_part = self.keypoint_to_face_part(idx + 1)\n",
    "                            data.append({\n",
    "                                \"infant_id\": int(infant_id),\n",
    "                                \"frame_id\": frame_id,\n",
    "                                \"keypoint\": tuple(kp),\n",
    "                                \"keypoint_score\": score,\n",
    "                                \"face_part\": face_part,\n",
    "                                \"keypoint_index\": idx + 1\n",
    "                            })\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing infant ID: 000122\n",
      "Processing infant ID: 000349\n",
      "Processing infant ID: 000011\n",
      "Processing infant ID: 000190\n",
      "Processing infant ID: 000369\n",
      "Processing infant ID: 000079\n",
      "Processing infant ID: 000360\n",
      "Processing infant ID: 000059\n",
      "Processing infant ID: 000111\n",
      "Processing infant ID: 000110\n",
      "Processing infant ID: 000364\n",
      "Processing infant ID: 000072\n",
      "Processing infant ID: 000000\n",
      "Processing infant ID: 000366\n",
      "Processing infant ID: 000346\n",
      "Processing infant ID: 000140\n",
      "Processing infant ID: 000365\n",
      "Processing infant ID: 000169\n",
      "Processing infant ID: 000285\n",
      "Processing infant ID: 000343\n",
      "Processing infant ID: 000241\n",
      "Processing infant ID: 000353\n",
      "Processing infant ID: 000127\n",
      "Processing infant ID: 000071\n",
      "Processing infant ID: 000173\n",
      "Processing infant ID: 000090\n",
      "Processing infant ID: 000001\n",
      "Processing infant ID: 000121\n",
      "Processing infant ID: 000021\n",
      "Processing infant ID: 000052\n",
      "Processing infant ID: 000342\n",
      "Processing infant ID: 000244\n",
      "Processing infant ID: 000099\n",
      "Processing infant ID: 000179\n",
      "Processing infant ID: 000348\n",
      "Processing infant ID: 000088\n",
      "Processing infant ID: 000347\n",
      "Processing infant ID: 000123\n",
      "Processing infant ID: 000089\n",
      "Processing infant ID: 000077\n",
      "Processing infant ID: 000358\n",
      "Processing infant ID: 000031\n",
      "Processing infant ID: 000112\n",
      "Processing infant ID: 000172\n",
      "Processing infant ID: 000005\n",
      "Processing infant ID: 000282\n",
      "Processing infant ID: 000338\n",
      "Processing infant ID: 000191\n",
      "Processing infant ID: 000086\n",
      "Processing infant ID: 000135\n",
      "Processing infant ID: 000352\n",
      "Processing infant ID: 000344\n",
      "Processing infant ID: 000070\n",
      "Processing infant ID: 000227\n",
      "Processing infant ID: 000339\n",
      "Processing infant ID: 000106\n",
      "Processing infant ID: 000141\n",
      "Processing infant ID: 000340\n",
      "Processing infant ID: 000073\n",
      "Processing infant ID: 000047\n",
      "Processing infant ID: 000068\n",
      "Processing infant ID: 000107\n",
      "Processing infant ID: 000186\n",
      "Processing infant ID: 000345\n",
      "Processing infant ID: 000341\n",
      "Dataset saved successfully as keypoints_dataset.csv.\n"
     ]
    }
   ],
   "source": [
    "json_dir = r'annotations' \n",
    "dataset = KeypointsDataset(json_dir)\n",
    "df = pd.DataFrame(dataset.data)\n",
    "\n",
    "# save the dataframe to CSV\n",
    "df.to_csv('keypoints_dataset.csv', index=False)\n",
    "\n",
    "print(\"Dataset saved successfully as keypoints_dataset.csv.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
