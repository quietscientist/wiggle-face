{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing infant ID: 023 on date: 2022_08_22, camera: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|██████████| 6637/6637 [00:19<00:00, 334.51it/s]\n",
      "Processing videos: 100%|██████████| 6637/6637 [01:36<00:00, 68.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved successfully as /workspaces/wiggle-face/data/panda_each_video/panda1_features_complete/r_2022_08_22_833180_023_cam3_vid4.csv\n",
      "Processing infant ID: 079 on date: 2023_12_06, camera: 3\n",
      "No frames with average confidence over 0.8 in r_2023_12_06_833180_079_cam3_vid4.json\n",
      "No blocks of at least 10 consecutive frames with average confidence over 0.75 in r_2023_12_06_833180_079_cam3_vid4.json\n",
      "Processing infant ID: 037 on date: 2022_09_01, camera: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|██████████| 2872/2872 [00:08<00:00, 334.16it/s]\n",
      "Processing videos: 100%|██████████| 2872/2872 [00:36<00:00, 77.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved successfully as /workspaces/wiggle-face/data/panda_each_video/panda1_features_complete/r_2022_09_01_833180_037_cam3_vid4.csv\n",
      "Processing infant ID: 080 on date: 2023_12_06, camera: 3\n",
      "No frames with average confidence over 0.8 in r_2023_12_06_833180_080_cam3_vid4.json\n",
      "No blocks of at least 10 consecutive frames with average confidence over 0.75 in r_2023_12_06_833180_080_cam3_vid4.json\n",
      "Processing infant ID: 047 on date: 2022_09_21, camera: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|██████████| 5934/5934 [00:17<00:00, 340.00it/s]\n",
      "Processing videos: 100%|██████████| 5934/5934 [01:25<00:00, 69.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved successfully as /workspaces/wiggle-face/data/panda_each_video/panda1_features_complete/r_2022_09_21_833180_047_cam3_vid4.csv\n",
      "Processing infant ID: 082 on date: 2024_01_24, camera: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|██████████| 42/42 [00:00<00:00, 343.46it/s]\n",
      "Processing videos: 100%|██████████| 42/42 [00:00<00:00, 83.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved successfully as /workspaces/wiggle-face/data/panda_each_video/panda1_features_complete/r_2024_01_24_833180_082_cam3_vid4.csv\n",
      "Processing infant ID: 054 on date: 2022_12_13, camera: 3\n",
      "No blocks of at least 10 consecutive frames with average confidence over 0.75 in r_2022_12_13_833180_054_cam3_vid4.json\n",
      "Processing infant ID: 086 on date: 2024_03_20, camera: 3\n",
      "No blocks of at least 10 consecutive frames with average confidence over 0.75 in r_2024_03_20_833180_086_cam3_vid4.json\n",
      "Processing infant ID: 056 on date: 2023_01_18, camera: 3\n",
      "No frames with average confidence over 0.8 in r_2023_01_18_833180_056_cam3_vid4.json\n",
      "No blocks of at least 10 consecutive frames with average confidence over 0.75 in r_2023_01_18_833180_056_cam3_vid4.json\n",
      "Processing infant ID: 005 on date: 2021_08_17, camera: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|██████████| 492/492 [00:01<00:00, 341.14it/s]\n",
      "Processing videos: 100%|██████████| 492/492 [00:05<00:00, 82.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved successfully as /workspaces/wiggle-face/data/panda_each_video/panda1_features_complete/r_2021_08_17_833180_005_cam3_vid4.csv\n",
      "Processing infant ID: 061 on date: 2023_02_10, camera: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|██████████| 672/672 [00:01<00:00, 338.57it/s]\n",
      "Processing videos: 100%|██████████| 672/672 [00:08<00:00, 80.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved successfully as /workspaces/wiggle-face/data/panda_each_video/panda1_features_complete/r_2023_02_10_833180_061_cam3_vid4.csv\n",
      "Processing infant ID: 040 on date: 2022_09_06, camera: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|██████████| 5099/5099 [00:14<00:00, 341.04it/s]\n",
      "Processing videos: 100%|██████████| 5099/5099 [01:12<00:00, 70.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved successfully as /workspaces/wiggle-face/data/panda_each_video/panda1_features_complete/r_2022_09_06_833180_040_cam3_vid4.csv\n",
      "Processing infant ID: 062 on date: 2023_03_30, camera: 3\n",
      "No frames with average confidence over 0.8 in r_2023_03_30_833180_062_cam3_vid4.json\n",
      "No blocks of at least 10 consecutive frames with average confidence over 0.75 in r_2023_03_30_833180_062_cam3_vid4.json\n",
      "Processing infant ID: 083 on date: 2024_04_10, camera: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|██████████| 1016/1016 [00:02<00:00, 342.13it/s]\n",
      "Processing videos: 100%|██████████| 1016/1016 [00:12<00:00, 80.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved successfully as /workspaces/wiggle-face/data/panda_each_video/panda1_features_complete/r_2024_04_10_833180_083_cam3_vid4.csv\n",
      "Processing infant ID: 063 on date: 2023_04_11, camera: 3\n",
      "No frames with average confidence over 0.8 in r_2023_04_11_833180_063_cam3_vid4.json\n",
      "No blocks of at least 10 consecutive frames with average confidence over 0.75 in r_2023_04_11_833180_063_cam3_vid4.json\n",
      "Processing infant ID: 006 on date: 2021_08_18, camera: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|██████████| 5199/5199 [00:15<00:00, 341.97it/s]\n",
      "Processing videos:  82%|████████▏ | 4247/5199 [01:00<00:13, 69.09it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage import median_filter\n",
    "\n",
    "class KeypointsDataset:\n",
    "    def __init__(self, json_dir, output_dir, batch_size=200000):\n",
    "        self.json_dir = json_dir\n",
    "        self.output_dir = output_dir\n",
    "        self.json_files = [f for f in os.listdir(json_dir) if f.endswith('.json')]\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "    def keypoint_to_face_part(self, index):\n",
    "        if 1 <= index <= 33:\n",
    "            return 0  # Do not load in df\n",
    "        elif 34 <= index <= 42:\n",
    "            return \"Right_brow\"\n",
    "        elif 43 <= index <= 51:\n",
    "            return \"Left_brow\"\n",
    "        elif 52 <= index <= 66:\n",
    "            if 56 <= index <= 66:\n",
    "                return 0  # Do not load in df\n",
    "            return \"Nose\"\n",
    "        elif 67 <= index <= 75:\n",
    "            return \"Right_Eye\"\n",
    "        elif 76 <= index <= 84:\n",
    "            return \"Left_Eye\"\n",
    "        elif 85 <= index <= 104:\n",
    "            return \"Mouth\"\n",
    "        elif index == 105 or index == 106:\n",
    "            return 0  # Do not load in df\n",
    "\n",
    "    def apply_filters(self, df):\n",
    "        # Apply mean filter across frames for each keypoint index\n",
    "        df['mean_keypoint_x'] = df.groupby('keypoint_index')['keypoint_x'].rolling(window=3, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "        df['mean_keypoint_y'] = df.groupby('keypoint_index')['keypoint_y'].rolling(window=3, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "        \n",
    "        # Apply median filter on the mean-filtered data across frames for each keypoint index\n",
    "        df['median_keypoint_x'] = df.groupby('keypoint_index')['mean_keypoint_x'].transform(lambda x: median_filter(x, size=3))\n",
    "        df['median_keypoint_y'] = df.groupby('keypoint_index')['mean_keypoint_y'].transform(lambda x: median_filter(x, size=3))\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def move_and_rotate_keypoints_updated(self, df):\n",
    "        def get_rotation_matrix(angle):\n",
    "            return np.array([\n",
    "                [np.cos(angle), -np.sin(angle)],\n",
    "                [np.sin(angle), np.cos(angle)]\n",
    "            ])\n",
    "\n",
    "        def rotate_points(points, angle):\n",
    "            rotation_matrix = get_rotation_matrix(angle)\n",
    "            return np.dot(points, rotation_matrix.T)\n",
    "\n",
    "        def normalize_points(points):\n",
    "            min_vals = points.min(axis=0)\n",
    "            max_vals = points.max(axis=0)\n",
    "            scale = max(max_vals - min_vals)\n",
    "            normalized_points = 2 * ((points - min_vals) / scale) - 1\n",
    "            return normalized_points\n",
    "\n",
    "        def sum_abs_x(angle):\n",
    "            rotated = rotate_points(translated_coords_np, angle)\n",
    "            return np.sum(np.abs(rotated[:, 0]))\n",
    "\n",
    "        result = []\n",
    "\n",
    "        # keypoint indexes to be aligned\n",
    "        align_keypoints = [52, 53, 54, 55, 88, 94]\n",
    "\n",
    "        grouped = df.groupby(['infant_id', 'frame_id'])\n",
    "        \n",
    "        for (infant_id, frame_id), group in tqdm(grouped, desc=\"Processing frames\"):\n",
    "            if group[group['keypoint_index'] == 55].empty:\n",
    "                continue\n",
    "            \n",
    "            kp_54 = cp.array(group[group['keypoint_index'] == 55][['x_coordinate', 'y_coordinate']].values[0])\n",
    "            \n",
    "            # coordinates of the keypoints to be aligned\n",
    "            keypoints_to_align = cp.array(group[group['keypoint_index'].isin(align_keypoints)][['x_coordinate', 'y_coordinate']].values)\n",
    "            translated_coords = keypoints_to_align - kp_54\n",
    "            translated_coords_np = translated_coords.get()\n",
    "            \n",
    "            # optimal angle to minimize the sum of absolute x-coordinates\n",
    "            angles = np.linspace(-np.pi, np.pi, 360)\n",
    "            optimal_angle = angles[np.argmin([sum_abs_x(a) for a in angles])]\n",
    "            \n",
    "            # translate all keypoints relative to kp_54\n",
    "            all_translated_coords = cp.array(group[['x_coordinate', 'y_coordinate']].values) - kp_54\n",
    "        \n",
    "            all_translated_coords_np = all_translated_coords.get()\n",
    "            rotated_coords = rotate_points(all_translated_coords_np, optimal_angle)\n",
    "            normalized_coords = normalize_points(rotated_coords)\n",
    "\n",
    "            kp_52_y = normalized_coords[group['keypoint_index'].values == 52][0, 1]\n",
    "            \n",
    "            if kp_52_y < 0:\n",
    "                normalized_coords = rotate_points(normalized_coords, np.pi)\n",
    "\n",
    "            transformed_group = group.copy()\n",
    "            transformed_group[['x_coordinate', 'y_coordinate']] = normalized_coords\n",
    "            \n",
    "            result.append(transformed_group)\n",
    "        \n",
    "        if not result:\n",
    "            return pd.DataFrame()  # Return an empty DataFrame if no frames are processed\n",
    "    \n",
    "        return pd.concat(result).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    def calculate_features(self, df):\n",
    "        def mean_y_coordinate(indices, mask):\n",
    "            return cp.mean(cp_df['y_coordinate'][mask & cp.isin(cp_df['keypoint_index'], indices)])\n",
    "\n",
    "        def mean_distance(pairs, mask):\n",
    "            distances = []\n",
    "            for (p1, p2) in pairs:\n",
    "                mask1 = mask & (cp_df['keypoint_index'] == p1)\n",
    "                mask2 = mask & (cp_df['keypoint_index'] == p2)\n",
    "                if cp.any(mask1) and cp.any(mask2):\n",
    "                    distances.append(cp.abs(cp.mean(cp_df['y_coordinate'][mask1]) - cp.mean(cp_df['y_coordinate'][mask2])))\n",
    "            return cp.mean(cp.array(distances))\n",
    "\n",
    "        def diff_x_coordinates(idx1, idx2, mask):\n",
    "            x1 = cp.mean(cp_df['x_coordinate'][mask & (cp_df['keypoint_index'] == idx1)])\n",
    "            x2 = cp.mean(cp_df['x_coordinate'][mask & (cp_df['keypoint_index'] == idx2)])\n",
    "            return cp.abs(x1 - x2)\n",
    "\n",
    "        def euclidean_distance(idx1, idx2, mask):\n",
    "            x1 = cp.mean(cp_df['x_coordinate'][mask & (cp_df['keypoint_index'] == idx1)])\n",
    "            y1 = cp.mean(cp_df['y_coordinate'][mask & (cp_df['keypoint_index'] == idx1)])\n",
    "            x2 = cp.mean(cp_df['x_coordinate'][mask & (cp_df['keypoint_index'] == idx2)])\n",
    "            y2 = cp.mean(cp_df['y_coordinate'][mask & (cp_df['keypoint_index'] == idx2)])\n",
    "            return cp.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "\n",
    "        def calculate_curvature_cp(x_coords, y_coords, mask):\n",
    "            x_coords_filtered = x_coords[mask]\n",
    "            y_coords_filtered = y_coords[mask]\n",
    "\n",
    "            if len(x_coords_filtered) < 3 or len(y_coords_filtered) < 3:\n",
    "                return cp.nan  # Need at least 3 points to calculate second derivative\n",
    "\n",
    "            # First derivatives\n",
    "            dx = cp.gradient(x_coords_filtered)\n",
    "            dy = cp.gradient(y_coords_filtered)\n",
    "\n",
    "            # Second derivatives\n",
    "            ddx = cp.gradient(dx)\n",
    "            ddy = cp.gradient(dy)\n",
    "\n",
    "            # Curvature calculation\n",
    "            curvature_numer = cp.abs(dx * ddy - dy * ddx)\n",
    "            curvature_denom = cp.power(dx**2 + dy**2, 1.5)\n",
    "            \n",
    "            # Handle divisions by zero and invalid values by setting them to zero\n",
    "            curvature_denom = cp.where(curvature_denom == 0, cp.nan, curvature_denom)\n",
    "            curvatures = curvature_numer / curvature_denom\n",
    "\n",
    "            # Replace NaN values with zero curvature\n",
    "            curvatures = cp.nan_to_num(curvatures, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "            # Mean curvature\n",
    "            mean_curvature = cp.mean(curvatures)\n",
    "\n",
    "            return mean_curvature\n",
    "\n",
    "\n",
    "        left_brow_indices = cp.array(range(34, 43))\n",
    "        right_brow_indices = cp.array(range(43, 52))\n",
    "        keypoint_pairs = {\n",
    "            'right_eye': [(79, 81), (78, 82), (77, 83)],\n",
    "            'left_eye': [(70, 72), (69, 73), (68, 74)],\n",
    "            'lips': [(100, 102), (99, 103), (98, 104)]\n",
    "        }\n",
    "\n",
    "        indices_dict = {\n",
    "            'upper_right_brow': cp.array(range(43, 48)),\n",
    "            'lower_right_brow': cp.array(range(48, 52)),\n",
    "            'upper_left_brow': cp.array(range(34, 39)),\n",
    "            'lower_left_brow': cp.array(range(39, 43)),\n",
    "            'upper_left_eyelid': cp.array(range(67, 72)),\n",
    "            'lower_left_eyelid': cp.array(range(72, 75)),\n",
    "            'upper_right_eyelid': cp.array(range(76, 81)),\n",
    "            'lower_right_eyelid': cp.array(range(81, 84)),\n",
    "            'upper_outer_lip': cp.array(range(85, 92)),\n",
    "            'lower_outer_lip': cp.array(range(92, 98)),\n",
    "            'upper_inner_lip': cp.array(range(98, 102)),\n",
    "            'lower_inner_lip': cp.array(range(102, 105))\n",
    "        }\n",
    "\n",
    "        cp_df = {\n",
    "            'infant_id': cp.array(df['infant_id'].values),\n",
    "            'date': cp.array(df['date'].values),\n",
    "            'cam': cp.array(df['cam'].values),\n",
    "            'frame_id': cp.array(df['frame_id'].values),\n",
    "            'keypoint_index': cp.array(df['keypoint_index'].values),\n",
    "            'x_coordinate': cp.array(df['x_coordinate'].values),\n",
    "            'y_coordinate': cp.array(df['y_coordinate'].values)\n",
    "        }\n",
    "\n",
    "        results = []\n",
    "        for (infant_id, date, cam, frame_id), group in tqdm(df.groupby(['infant_id', 'date', 'cam', 'frame_id']), desc=\"Processing videos\"):\n",
    "            mask = (cp_df['infant_id'] == infant_id) & (cp_df['date'] == date) & (cp_df['cam'] == cam) & (cp_df['frame_id'] == frame_id)\n",
    "            curvatures = {f'curvature_{key}': calculate_curvature_cp(cp_df['x_coordinate'], cp_df['y_coordinate'], mask & cp.isin(cp_df['keypoint_index'], indices)).get() for key, indices in indices_dict.items()}\n",
    "            features = {\n",
    "                'right_brow_mean_y': mean_y_coordinate(right_brow_indices, mask).get(),\n",
    "                'left_brow_mean_y': mean_y_coordinate(left_brow_indices, mask).get(),\n",
    "                'right_eye_distance': mean_distance(keypoint_pairs['right_eye'], mask).get(),\n",
    "                'left_eye_distance': mean_distance(keypoint_pairs['left_eye'], mask).get(),\n",
    "                'lips_distance': mean_distance(keypoint_pairs['lips'], mask).get(),\n",
    "                'left_eye_width': diff_x_coordinates(67, 71, mask).get(),\n",
    "                'right_eye_width': diff_x_coordinates(76, 80, mask).get(),\n",
    "                'left_eyebrow_width': diff_x_coordinates(34, 39, mask).get(),\n",
    "                'right_eyebrow_width': diff_x_coordinates(47, 51, mask).get(),\n",
    "                'lip_width': diff_x_coordinates(85, 91, mask).get(),\n",
    "                'left_eye_upper_corner_left_eyebrow_center_dist': euclidean_distance(67, 41, mask).get(),\n",
    "                'right_eye_upper_corner_and_right_eyebrow_center_dist': euclidean_distance(80, 49, mask).get(),\n",
    "                'nose_centre_lips_centre_dist': diff_x_coordinates(55, 99, mask).get(),\n",
    "                'left_eye_lower_corner_lips_left_corner_dist': euclidean_distance(85, 71, mask).get(),\n",
    "                'right_eye_lower_corner_lips_right_corner_dist': euclidean_distance(76, 91, mask).get(),\n",
    "                'left_eye_upper_corner_lips_left_corner_dist': euclidean_distance(85, 67, mask).get(),\n",
    "                'right_eye_upper_corner_lips_right_corner_dist': euclidean_distance(80, 91, mask).get(),\n",
    "                **curvatures\n",
    "            }\n",
    "\n",
    "            results.append({\n",
    "                'infant_id': infant_id,\n",
    "                'date': date,\n",
    "                'cam': cam,\n",
    "                'frame_id': frame_id,\n",
    "                **features\n",
    "            })\n",
    "\n",
    "        if not results:\n",
    "            return pd.DataFrame()  # Return an empty DataFrame if no results are generated\n",
    "        \n",
    "        results_df = pd.DataFrame(results)\n",
    "        return results_df\n",
    "\n",
    "    def save_to_csv(self, df, filename):\n",
    "        if df.empty:\n",
    "            print(f\"No data to save for {filename}\")\n",
    "            return\n",
    "\n",
    "        output_path = os.path.join(self.output_dir, filename)\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Dataset saved successfully as {output_path}\")\n",
    "\n",
    "    def process_and_save(self, json_file):\n",
    "        video_id = os.path.splitext(json_file)[0]\n",
    "        parts = video_id.split('_')\n",
    "        date = '_'.join(parts[1:4])\n",
    "        infant_id = parts[5]\n",
    "        camera = parts[6]\n",
    "\n",
    "        cam = ord(camera[3:4]) - ord('0')\n",
    "        print(f\"Processing infant ID: {infant_id} on date: {date}, camera: {cam}\")\n",
    "        with open(os.path.join(self.json_dir, json_file), 'r') as f:\n",
    "            frames = json.load(f)\n",
    "            frame_data_list = []\n",
    "\n",
    "            for frame_index, frame_data in enumerate(frames):\n",
    "                frame_id = frame_data[\"frame_id\"]\n",
    "                for instance_index, instance in enumerate(frame_data[\"instances\"]):\n",
    "                    keypoints = instance[\"keypoints\"]\n",
    "                    keypoint_scores = instance[\"keypoint_scores\"]\n",
    "\n",
    "                    for idx, (kp, score) in enumerate(zip(keypoints, keypoint_scores)):\n",
    "                        face_part = self.keypoint_to_face_part(idx + 1)\n",
    "                        if face_part != 0:\n",
    "                            frame_data_list.append({\n",
    "                                \"infant_id\": int(infant_id),\n",
    "                                \"date\": date,\n",
    "                                \"cam\": cam,\n",
    "                                \"frame_id\": frame_id,\n",
    "                                \"keypoint\": kp,\n",
    "                                \"keypoint_score\": score,\n",
    "                                \"face_part\": face_part,\n",
    "                                \"keypoint_index\": idx + 1,\n",
    "                                \"keypoint_x\": kp[0],\n",
    "                                \"keypoint_y\": kp[1]\n",
    "                            })\n",
    "\n",
    "            df = pd.DataFrame(frame_data_list)\n",
    "            if df.empty:\n",
    "                print(f\"No valid data in {json_file}\")\n",
    "                return\n",
    "\n",
    "            df = self.apply_filters(df)\n",
    "            df[['x_coordinate', 'y_coordinate']] = pd.DataFrame(df['keypoint'].tolist(), index=df.index)\n",
    "            df = df.drop(columns=['keypoint'])\n",
    "            df['date'] = pd.to_datetime(df['date'], format='%Y_%m_%d')\n",
    "            df['date'] = (df['date'] - pd.Timestamp('1970-01-01')) // pd.Timedelta('1D')\n",
    "    \n",
    "            # Filter by average confidence over 0.8\n",
    "            df['average_confidence'] = df.groupby('frame_id')['keypoint_score'].transform('mean')\n",
    "            df = df[df['average_confidence'] >= 0.8]\n",
    "\n",
    "            if df.empty:\n",
    "                print(f\"No frames with average confidence over 0.8 in {json_file}\")\n",
    "            else:\n",
    "                # Identify consecutive frames blocks with at least 10 frames\n",
    "                df = df.sort_values(by=['keypoint_index','frame_id'])\n",
    "                df = df.reset_index(drop=True)\n",
    "                df['frame_diff'] = df['frame_id'].diff().fillna(1)\n",
    "                df['block'] = (df['frame_diff'] != 1).cumsum()\n",
    "                blocks = df.groupby('block').filter(lambda x: len(x) >= 10)\n",
    "                df = blocks.drop(columns=['block', 'frame_diff'])\n",
    "                \n",
    "\n",
    "            if df.empty:\n",
    "                print(f\"No blocks of at least 10 consecutive frames with average confidence over 0.75 in {json_file}\")\n",
    "                return\n",
    "\n",
    "            df = self.move_and_rotate_keypoints_updated(df)\n",
    "            if df.empty:\n",
    "                print(f\"No valid keypoints to process in {json_file}\")\n",
    "                return\n",
    "\n",
    "            df = self.calculate_features(df)\n",
    "            if df.empty:\n",
    "                print(f\"No features to save for {json_file}\")\n",
    "                return\n",
    "\n",
    "            self.save_to_csv(df, f\"{video_id}.csv\")\n",
    "\n",
    "    def load_data(self):\n",
    "        for json_file in self.json_files:\n",
    "            self.process_and_save(json_file)\n",
    "        print(\"All files processed and saved.\")\n",
    "\n",
    "# Usage\n",
    "json_dir = '/workspaces/wiggle-face/data-ioana/PANDA1/r_face_infant_visible/annotations'\n",
    "output_dir = '/workspaces/wiggle-face/data/panda_each_video/panda1_features_complete'\n",
    "dataset = KeypointsDataset(json_dir, output_dir)\n",
    "dataset.load_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
